import json
import csv
import glob
import os

# --- 1. å®šç¾© Ontology æ¬„ä½é †åº ---
ONTOLOGY_COLUMNS = [
    # æ ¸å¿ƒè­˜åˆ¥
    "node_internal_name", "node_display_name", "node_description", "node_version", "node_category",
    # é€£æ¥æ¶æ§‹
    "input_types", "output_types", "credential_types", "icon_name",
    # äº’å‹•æ¨¡å¼
    "interaction_model", "trigger_type", "trigger_interval",
    # åŠŸèƒ½åˆ†é¡
    "resources", "operations", "events", "generic_methods",
    # è³‡æ–™è™•ç†
    "binary_handling", "supported_file_formats", "data_transformation",
    # åƒæ•¸ç‰¹å¾µ
    "standard_parameters", "pagination_mode", "dynamic_parameters", "complex_ui_elements",
    # AI èˆ‡ Meta
    "ai_features", "ai_model_parameters", "documentation_url", "special_notices"
]

def extract_options(parameter):
    """å¾åƒæ•¸ä¸­æå– options åˆ—è¡¨"""
    if not parameter or 'options' not in parameter:
        return []
    return [opt.get('name', opt.get('value')) for opt in parameter['options']]

def map_node_to_ontology(node):
    """å°‡å–®ä¸€ n8n ç¯€é» JSON æ˜ å°„åˆ° Ontology æ¬„ä½"""
    
    # åˆå§‹åŒ–ç©ºè³‡æ–™
    data = {col: "" for col in ONTOLOGY_COLUMNS}
    
    # 1. æ ¸å¿ƒè­˜åˆ¥
    data['node_internal_name'] = node.get('name', '')
    data['node_display_name'] = node.get('displayName', '')
    data['node_description'] = node.get('description', '')
    data['node_version'] = node.get('version', 1)
    # Icon é€šå¸¸åœ¨åŸå§‹ç¢¼ä¸­ï¼Œé€™è£¡å˜—è©¦è®€å– defaults
    data['icon_name'] = node.get('icon', '') 
    
    # 2. æ¨æ–· Input/Output (ç°¡æ˜“é‚è¼¯)
    # n8n JSON é€šå¸¸ä¸ç›´æ¥å¯« inputs/outputsï¼Œéœ€ä¾è³´ inputs å±¬æ€§æˆ–é è¨­å€¼
    data['input_types'] = str(node.get('inputs', []))
    data['output_types'] = str(node.get('outputs', []))
    
    # 3. å±¬æ€§éæ­· (Properties Loop)
    properties = node.get('properties', [])
    
    resources = set()
    operations = set()
    events = set()
    std_params = set()
    complex_ui = set()
    
    has_binary = False
    
    for prop in properties:
        p_name = prop.get('name', '')
        p_type = prop.get('type', '')
        
        # æ­¸é¡ Resource/Operation/Event
        if p_name == 'resource':
            resources.update(extract_options(prop))
        elif p_name == 'operation':
            operations.update(extract_options(prop))
        elif p_name == 'event' or p_name == 'events':
            events.update(extract_options(prop))
            
        # åµæ¸¬æ¨™æº–åƒæ•¸
        if p_name in ['limit', 'returnAll', 'simple']:
            std_params.add(p_name)
            
        # åµæ¸¬äºŒé€²ä½è™•ç†
        if p_name == 'binaryPropertyName' or p_type == 'binary':
            has_binary = True
            
        # åµæ¸¬è¤‡é›œ UI
        if p_type in ['collection', 'fixedCollection', 'json']:
            complex_ui.add(p_name)

    # 4. å¡«å…¥é›†åˆè³‡æ–™ (è½‰æ›ç‚ºå­—ä¸²ä»¥å­˜å…¥ CSV)
    data['resources'] = str(list(resources)) if resources else ""
    data['operations'] = str(list(operations)) if operations else ""
    data['events'] = str(list(events)) if events else ""
    data['standard_parameters'] = str(list(std_params))
    data['complex_ui_elements'] = str(list(complex_ui))
    data['binary_handling'] = str(has_binary)
    
    # 5. æ¨æ–· Interaction Model (è¦å‰‡å¼•æ“)
    display_name = data['node_display_name'].lower()
    if 'trigger' in display_name:
        data['interaction_model'] = 'Trigger'
        data['trigger_type'] = 'Webhook' if 'webhook' in data['node_description'].lower() else 'Polling'
    elif 'agent' in display_name or 'chain' in display_name:
        data['interaction_model'] = 'Logic'
        data['ai_features'] = str(['AI Integration'])
    elif resources:
        data['interaction_model'] = 'Resource-Based'
    else:
        data['interaction_model'] = 'Generic-API'

    return data

def main():
    # 1. æœå°‹æ‰€æœ‰ batch JSON æª”æ¡ˆ
    files = glob.glob('batch_*.json')
    files.sort()
    
    if not files:
        print("âŒ æ‰¾ä¸åˆ° batch_*.json æª”æ¡ˆï¼Œè«‹ç¢ºèªè·¯å¾‘ã€‚")
        return

    all_rows = []
    print(f"ğŸ” ç™¼ç¾ {len(files)} å€‹æª”æ¡ˆï¼Œé–‹å§‹è™•ç†...")

    # 2. è®€å–ä¸¦è™•ç†æ¯å€‹æª”æ¡ˆ
    for file_path in files:
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = json.load(f)
                
                # è™•ç† content æ˜¯ List é‚„æ˜¯ Dict çš„æƒ…æ³
                nodes = []
                if isinstance(content, list):
                    nodes = content
                elif isinstance(content, dict) and 'nodes' in content:
                    nodes = content['nodes']
                else:
                    # å¦‚æœæ˜¯å–®ä¸€ç¯€é»çµæ§‹
                    nodes = [content]

                for node in nodes:
                    # éƒ¨åˆ†æª”æ¡ˆå¯èƒ½åŒ…äº†ä¸€å±¤ fullContent
                    target_node = node.get('fullContent', node)
                    row = map_node_to_ontology(target_node)
                    all_rows.append(row)
                    
        except Exception as e:
            print(f"âš ï¸ è™•ç†æª”æ¡ˆ {file_path} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

    # 3. è¼¸å‡º CSV
    output_file = 'n8n_ontology_full_list.csv'
    with open(output_file, 'w', encoding='utf-8-sig', newline='') as f:
        writer = csv.DictWriter(f, fieldnames=ONTOLOGY_COLUMNS)
        writer.writeheader()
        writer.writerows(all_rows)

    print(f"\nâœ… æˆåŠŸï¼å·²å°‡ {len(all_rows)} å€‹ç¯€é»è½‰æ›ç‚º '{output_file}'")
    print("ğŸ‘‰ CSV æ ¼å¼å·²è‡ªå‹•è™•ç†å¼•è™Ÿèˆ‡é€—è™Ÿå•é¡Œï¼Œå¯ç›´æ¥ç”¨ Excel é–‹å•Ÿã€‚")

if __name__ == "__main__":
    main()